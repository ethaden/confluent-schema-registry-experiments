= Experiments with Confluent Schema Registry

== Building the code

Building the code using gradle:

```shell
./gradlew build
```

Potentially, you might need to update gradle first:

```shell
gradle wrapper
```

== Running the code

First, start the docker environment:

```shell
docker compose up -d
```
Create a new topic:

```shell
docker compose exec broker kafka-topics --bootstrap-server broker:9092 --topic measurements --create
```

For this demo, we use the https://jqlang.org/[`jq`] command for preparing the payload to be sent to the Schema Registry for uploading the schema.
The first parameter of the script is the input file to read, the second parameter specifies the `application.major.version`, an advanced commercial feature of Schema Registry (please find more details https://docs.confluent.io/cloud/current/sr/fundamentals/data-contracts.html#application-major-versioning[here]):

```shell
export MEASUREMENT1_SCHEMA_RAW=$(cat << 'eof'
{schema: $schema,
"metadata": { "properties": { "application.major.version": "1" } }
}
eof
)
export MEASUREMENT1_SCHEMA=$(jq -n --rawfile schema avro/measurement-v1.avsc "${MEASUREMENT1_SCHEMA_RAW}")
export MEASUREMENT2_SCHEMA_RAW=$(cat << 'eof'
{schema: $schema,
"metadata": { "properties": { "application.major.version": "2" } }
}
eof
)
export MEASUREMENT2_SCHEMA=$(jq -n --rawfile schema avro/measurement-v2.avsc "${MEASUREMENT2_SCHEMA_RAW}")
```

Configure the subject for advanced application version handling:

```shell
curl -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data '{ "compatibilityGroup": "application.major.version" }' \
http://localhost:8081/config/measurements-value
```

Note that the `compatibilityGroup` setting for Schema Registry is just a string which is then looked up in the metadata of the schemas. In some examples, the value "major_version" is used instead of `application.major.version`. As long as this is used concisely everywhere, this is absolutely possible. For simplicity, I would recommend using `application.major.version` and this is what is used in this example, too.

Register the first version of our schema by running:

```shell
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data "$MEASUREMENT1_SCHEMA" \
http://localhost:8081/subjects/measurements-value/versions
```

Show all schema versions:

```shell
curl schema-registry:8081/subjects/measurements-value/versions
```

Just for validation: Get schema with specific version (here: version 1):

```shell
curl -s schema-registry:8081/subjects/measurements-value/versions/1/schema | jq .
```

Note that you do not see the metadata of the schema with this query.
Particularly, you won't be able to see our `application.major.version` in the result.
In order to query also the metadata along with the schema (but only the latest), use this endpoint instead:

```shell
curl -s schema-registry:8081/subjects/measurements-value/metadata | jq .
```

If you want to query a specific major version schema, use this query
(here, we want to find the latest schema registered for the older version of the application):

```shell
curl -s schema-registry:8081/subjects/measurements-value/metadata?key="application.major.version"\&value="1" | jq .
```

Run producer with gradle:

```shell
./gradlew -p producer-schema-v1 run
```

Run consumer (for this demo, we use random group IDs each time the consumers are started):

```shell
./gradlew -p consumer-schema-v1 run
```

Now register the updated version of the schema which is NOT compatible in any way. This should work now as we provide a new application major version.

```shell
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data "$MEASUREMENT2_SCHEMA" \
http://localhost:8081/subjects/measurements-value/versions
```

Run a producer using the new schema, this time using our new custom Avro logical type `fixedpointnumber`:

```shell
./gradlew -p producer-schema-v2 run
```

Use the console consumer to show the values:

```shell
docker compose exec schema-registry kafka-avro-console-consumer --bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic measurements --from-beginning
```

As you can see, the primitive type used to encode the decimal number is `string`. Thus, we eliminated issues with the precision of the values, rouding, etc. However, this data type requires more more and cannot be used without conversions.

Now the topic should contain a mix of messages with Version 1 and Version 2 of the schema.
Try to consume the again with both the consumer knowing only Version 1 of the schema and the consumer knowing Version 2:

```shell
./gradlew -p consumer-schema-v1 run
```

With the newer version of the consumer:

```shell
./gradlew -p consumer-schema-v2 run
```

Both consumer will only be able to deserialize the messages which are in the format they know and show error messages for all others.



=== Schema Migration Rules

Let's configure Schema Migration Rule.s Note that the dependency `io.confluent:kafka-schema-rules` has been added to all Kafka clients already in the build environment. Migration rules are written in JSonata and uploaded to Schema Registry. Thus, we need to extend the existing schemas.

The following JSOnata string takes inputs such as the following (you can use https://try.jsonata.org/ for testing):

```json
{
  "Measurement": {
    "name": "Temperature",
    "value": 22.53,
    "unit": "°C"
  }
}
```

Upgrading the value from float/double to string can be done with this expression (works only for flat data strcutures as the example above):

```json
$merge([$, {'value': $string(Measurement.value)}])
```

Downgrading the value from string to float would be done by this expression:

```json
$merge([$, {'value': $number(Measurement.value)}])
```


Let's assemble the migration rules now. They look like this:


```shell
export MEASUREMENT2_SCHEMA_RAW=$(cat << 'eof'
{   schema: $schema,
    "metadata": { "properties": { "application.major.version": "2" } },
    "ruleSet": {
        "migrationRules": [
            {
            "name": "upgradeFloatValueToString",
            "kind": "TRANSFORM",
            "type": "JSONATA",
            "mode": "UPGRADE",
            "expr": "$merge([$, {'value': $string(Measurement.value)}])",
            "disabled": false
            },
            {
            "name": "downgradeStringValueToFloat",
            "kind": "TRANSFORM",
            "type": "JSONATA",
            "mode": "DOWNGRADE",
            "expr": "$merge([$, {'value': $number(Measurement.value)}])",
            "disabled": false
            }
        ]
    }
}
eof
)
export MEASUREMENT2_SCHEMA=$(jq -n --rawfile schema avro/measurement-v2.avsc "${MEASUREMENT2_SCHEMA_RAW}")
```

```shell
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data "$MEASUREMENT2_SCHEMA" \
http://localhost:8081/subjects/measurements-value/versions
```

Check if consumption works by restricting `kafka-avro-console-consumer` to the second application version:

```shell
docker compose exec schema-registry kafka-avro-console-consumer --bootstrap-server broker:9092 --property schema.registry.url=http://localhost:8081 --topic measurements --from-beginning --property print.schema.ids=true --property use.latest.with.metadata=application.major.version=2 --property rule.executors=executor1 --property rule.executors.executor1.class=io.confluent.kafka.schemaregistry.rules.jsonata.JsonataExecutor
```


== Helpful tools

=== Schema Registry


Get all known versions:

```shell
curl -H "Content-Type: application/vnd.schemaregistry.v1+json" http://localhost:8081/subjects/measurements-value/versions
```

Inspect a specific version (here: version 1):

```shell
curl -H "Content-Type: application/vnd.schemaregistry.v1+json" http://localhost:8081/subjects/measurements-value/versions/1
```

Soft delete a specific version:

```shell
curl -X DELETE -H "Content-Type: application/vnd.schemaregistry.v1+json" http://localhost:8081/subjects/measurements-value/versions/1
```

Permanently delete a specific version (you need to soft delete first):

```shell
curl -X DELETE -H "Content-Type: application/vnd.schemaregistry.v1+json" http://localhost:8081/subjects/measurements-value/versions/1?permanent=true
```


==== Playground: Commercial feature of Schema Registry: Application Major Versions
Let's play a bit with compatibility checks and application major versions.

First, we convert the two versions of our schema without using an application major version.

```shell
export MEASUREMENT1_SCHEMA=$(jq -n --rawfile schema avro/measurement-v1.avsc '{schema: $schema}')
export MEASUREMENT2_SCHEMA=$(jq -n --rawfile schema avro/measurement-v2.avsc '{schema: $schema}')
```

We put them one by one into the schema registry using a subject for another topic value (the topic does not exist, but this doesn't matter):

The first version of the schema:

```shell
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data "$TEST_SCHEMA1" \
http://localhost:8081/subjects/testtopic-value/versions
```

And the second version:

```shell
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data "$TEST_SCHEMA2" \
http://localhost:8081/subjects/testtopic-value/versions
```

The second command will raise an error because this version of the schema is not backward compatible to the first version! By default our schema registry enforces backward compatibility.

Let's wipe the first schema:

```shell
curl -X DELETE -H "Content-Type: application/vnd.schemaregistry.v1+json" http://localhost:8081/subjects/testtopic-value/versions/1
curl -X DELETE -H "Content-Type: application/vnd.schemaregistry.v1+json" http://localhost:8081/subjects/testtopic-value/versions/1?permanent=true
```

Check that it has been deleted:

```shell
curl -H "Content-Type: application/vnd.schemaregistry.v1+json" http://localhost:8081/subjects/testtopic-value/versions
```

Now convert both schemas again, this time with an application major version:

```shell
export MEASUREMENT1_SCHEMA_RAW=$(cat << 'eof'
{schema: $schema,
"metadata": { "properties": { "application.major.version": "1" } }
}
eof
)
export MEASUREMENT1_SCHEMA=$(jq -n --rawfile schema avro/measurement-v1.avsc "${MEASUREMENT1_SCHEMA_RAW}")
export MEASUREMENT2_SCHEMA_RAW=$(cat << 'eof'
{schema: $schema,
"metadata": { "properties": { "application.major.version": "2" } }
}
eof
)
export MEASUREMENT2_SCHEMA=$(jq -n --rawfile schema avro/measurement-v2.avsc "${MEASUREMENT2_SCHEMA_RAW}")
```

Upload the first version of the schema again:

```shell
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data "$TEST_SCHEMA1" \
http://localhost:8081/subjects/testtopic-value/versions
```

Now upload the second version of the same schema, which contains a breaking change again:

```shell
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data "$TEST_SCHEMA2" \
http://localhost:8081/subjects/testtopic-value/versions
```

It is still not working! The reason is that again the strict compatibility check prevents us from upload the schema with the breaking change.
First, we need to configure the subject in schema registry properly:

```shell
curl -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data '{ "compatibilityGroup": "application.major.version" }' \
http://localhost:8081/config/testtopic-value
```

You can check the current configuration like this:

```shell
curl http://localhost:8081/config/testtopic-value
```

Now the updated incompatible schema can be registered:

```shell
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data "$TEST_SCHEMA2" \
http://localhost:8081/subjects/testtopic-value/versions
```

=== CLI Consumer

Read messages via CLI tools, using standard console consumer:

```shell
docker compose exec broker kafka-console-consumer --bootstrap-server broker:9092 --topic measurements --from-beginning
```

Read messages via avro console consumer:

```shell
docker compose exec schema-registry kafka-avro-console-consumer --bootstrap-server broker:9092 --property schema.registry.url=http://localhost:8081 --topic measurements --from-beginning
```

You might want to delete the topic to start fresh between tests:

```shell
docker compose exec broker  kafka-topics --bootstrap-server broker:9092 --delete --topic measurements
```

Alternatively, if you just want to consume the same messages again with the Java consumer, just reset the consumer groups offset:

```shell
docker compose exec broker kafka-consumer-groups --bootstrap-server broker:9092 --group Consumer --reset-offsets --to-earliest --topic measurements --execute
```

You can view the offsets by running:

```shell
docker compose exec broker kafka-consumer-groups --bootstrap-server broker:9092 --group Consumer --describe
```

== Background: Migration Rules with JSonata

Just in case you use hierarchical data structures, here is an example where we do the conversion used above (casting the `value` field):

```json
{
  "Measurement": {
    "name": "Temperature",
    "location": "My location",
    "value": 22.53,
    "unit": "°C"
  }
}
```

It will output all values as is (that's what the `$` is for), except for the `value` field inside of `Measurement` which is casted to string first:

```json
$merge([$, {'Measurement': $merge([Measurement, {'value': $string(Measurement.value)}])}])
```

This expression will be used for `upgrading` existing messages in a topic.
Downgrading (e.g. to support older consumers), can be done with the analog expression:

```json
$merge([$, {'Measurement': $merge([Measurement, {'value': $number(Measurement.value)}])}])
```


== Shutting down, deleting containers

```shell
docker compose down -v
```

== Development

Check for dependency updates in each of the sub projects like this:

```shell
./gradlew -P producer dependencyUpdates -Drevision=release
```

Upgrade the dependency manually.

For upgrading the gradle version, you can use this:

```shell
gradle wrapper --gradle-version <gradle version>
```
